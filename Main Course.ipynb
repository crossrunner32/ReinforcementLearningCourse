{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stable-baselines3.readthedocs.io/en/master/guide/rl.html\n",
    "# https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html#a-taxonomy-of-rl-algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-1.6.0-py3-none-any.whl (177 kB)\n",
      "Collecting gym==0.21\n",
      "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.6.0)\n",
      "Requirement already satisfied: torch>=1.11 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.12.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.23.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.1.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.3.2)\n",
      "Requirement already satisfied: tensorboard>=2.2.0; extra == \"extra\" in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.10.0)\n",
      "Collecting opencv-python; extra == \"extra\"\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-win_amd64.whl (35.6 MB)\n",
      "Requirement already satisfied: protobuf~=3.19.0; extra == \"extra\" in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.19.1)\n",
      "Requirement already satisfied: pillow; extra == \"extra\" in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (8.0.1)\n",
      "Collecting autorom[accept-rom-license]~=0.4.2; extra == \"extra\"\n",
      "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
      "Collecting ale-py==0.7.4; extra == \"extra\"\n",
      "  Downloading ale_py-0.7.4-cp38-cp38-win_amd64.whl (904 kB)\n",
      "Requirement already satisfied: psutil; extra == \"extra\" in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (5.7.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (3.7.4.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2.8.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.10.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (50.3.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (2.3.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (3.3.6)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (0.35.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (1.42.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (2.24.0)\n",
      "Collecting importlib-resources; python_version < \"3.9\"\n",
      "  Downloading importlib_resources-5.9.0-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]) (4.50.2)\n",
      "Requirement already satisfied: click in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]) (7.1.2)\n",
      "Collecting AutoROM.accept-rom-license; extra == \"accept-rom-license\"\n",
      "  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting importlib-metadata>=4.10.0; python_version < \"3.10\"\n",
      "  Downloading importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->stable-baselines3[extra]) (1.15.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (3.0.4)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from importlib-resources; python_version < \"3.9\"->autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]) (3.4.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (3.1.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\petermeyerdr\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (0.4.8)\n",
      "Building wheels for collected packages: gym, AutoROM.accept-rom-license\n",
      "  Building wheel for gym (setup.py): started\n",
      "  Building wheel for gym (setup.py): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616827 sha256=dd1708852b1f933eb6c9e886ce6aabe9ff93c4db4925d83ca32d023077ff1127\n",
      "  Stored in directory: c:\\users\\petermeyerdr\\appdata\\local\\pip\\cache\\wheels\\27\\6d\\b3\\a3a6e10704795c9b9000f1ab2dc480dfe7bed42f5972806e73\n",
      "  Building wheel for AutoROM.accept-rom-license (PEP 517): started\n",
      "  Building wheel for AutoROM.accept-rom-license (PEP 517): finished with status 'done'\n",
      "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=446447 sha256=79b0f3cd6f6e2b69812f950618e2cd3d8df9a50ab8d613d2b9097564f87556c4\n",
      "  Stored in directory: c:\\users\\petermeyerdr\\appdata\\local\\pip\\cache\\wheels\\51\\08\\c5\\28b973078691a3f8baf99fcaec1ed8f0e05ef6e54d2390212c\n",
      "Successfully built gym AutoROM.accept-rom-license\n",
      "Installing collected packages: gym, opencv-python, importlib-resources, AutoROM.accept-rom-license, autorom, importlib-metadata, ale-py, stable-baselines3\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.8.2\n",
      "    Uninstalling importlib-metadata-4.8.2:\n",
      "      Successfully uninstalled importlib-metadata-4.8.2\n",
      "Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.4 autorom-0.4.2 gym-0.21.0 importlib-metadata-4.12.0 importlib-resources-5.9.0 opencv-python-4.6.0.66 stable-baselines3-1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]\n",
    "!pip install pyglet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym \n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"CartPole-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:38.0\n",
      "Episode:2 Score:13.0\n",
      "Episode:3 Score:15.0\n",
      "Episode:4 Score:33.0\n",
      "Episode:5 Score:14.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding The Environment\n",
    "https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-push cart to left, 1-push cart to the right\n",
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [cart position, cart velocity, pole angle, pole angular velocity]\n",
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train an RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make directories first\n",
    "log_path = os.path.join('Training', 'Logs')\n",
    "log_path = os.path.join('Training', 'Saved Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "#model = PPO('MlpPolicy', env, verbose = 1)\n",
    "model = PPO('MlpPolicy', env, verbose = 1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Saved Models\\PPO_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 650  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 3    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 522         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008295525 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | -0.0085     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.33        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 52.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 466          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105953105 |\n",
      "|    clip_fraction        | 0.0674       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.668       |\n",
      "|    explained_variance   | 0.0954       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0175      |\n",
      "|    value_loss           | 30.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2b92a7b60d0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save and Reload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_path = os.path.join('Training', 'Saved Models', 'PPO_Model_Cartpole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training\\\\Saved Models\\\\PPO_Model_Cartpole'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPO_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(PPO_path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Saved Models\\PPO_2\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 627  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 3    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 491         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006274679 |\n",
      "|    clip_fraction        | 0.0466      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.62       |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 56.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 480          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079595735 |\n",
      "|    clip_fraction        | 0.0805       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.612       |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0152      |\n",
      "|    value_loss           | 48.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2b932382730>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=5000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    env.render()\n",
    "    if done: \n",
    "        print('info', info)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Viewing Logs in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log_path = os.path.join(log_path, 'PPO_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir={training_log_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Adding a callback to the training Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'Saved Models')\n",
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=190, verbose=1)\n",
    "eval_callback = EvalCallback(env, \n",
    "                             callback_on_new_best=stop_callback, \n",
    "                             eval_freq=10000, \n",
    "                             best_model_save_path=save_path, \n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO('MlpPolicy', env, verbose = 1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('Training', 'Saved Models', 'best_model')\n",
    "model = PPO.load(model_path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Changing Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_arch=[dict(pi=[128, 128, 128, 128], vf=[128, 128, 128, 128])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO('MlpPolicy', env, verbose = 1, policy_kwargs={'net_arch': net_arch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Using an Alternate Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN('MlpPolicy', env, verbose = 1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_path = os.path.join('Training', 'Saved Models', 'DQN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(dqn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN.load(dqn_path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "913831768da4047a2e37deb59627c76854514afe5c4e022f240264e693999d73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
